
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Introduction to High-Performance Computing (HPC) &#8212; TheMulQuaBio</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=01a0bdc2" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/Appendix-HighPerformanceComputing';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="TMQB Coursework Assessment" href="Appendix-Assessment.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="TheMulQuaBio - Home"/>
    <img src="../_static/logo.png" class="logo__image only-dark pst-js-only" alt="TheMulQuaBio - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Welcome to The Multilingual Quantitative Biologist!
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Computing</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Unix.html">UNIX and Linux</a></li>
<li class="toctree-l1"><a class="reference internal" href="ShellScripting.html">Shell scripting</a></li>
<li class="toctree-l1"><a class="reference internal" href="Git.html">Version control with Git</a></li>
<li class="toctree-l1"><a class="reference internal" href="LaTeX.html">Scientific documents with <span class="math notranslate nohighlight">\(\LaTeX\)</span></a></li>
<li class="toctree-l1"><a class="reference internal" href="Python.html">Biological Computing in Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="R.html">Biological Computing in R</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Maths for Biologists</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../mathscourse/lecture01/01_Making_mathematical_statements.html">01 - Making mathematical statements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mathscourse/lecture02/02_Describing_shapes_and_patterns.html">02   - Describing shapes and patterns</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mathscourse/lecture03/03_Analysing_change%2C_one_step_at_a_time.html">03   - Analysing change, one step at a time</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mathscourse/lecture04/04_From_table_arrangements_to_powerful_tools.html">04 - From table arrangements to powerful tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mathscourse/lecture05/05_From_table_arrangements_to_powerful_tools_part2.html">05 - From table arrangements to powerful tools - part 2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mathscourse/lecture06/06_Analysing_change_continuously.html">06 - Analysing change, continuously</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mathscourse/lecture07/07_Analysing_change_continuously_part2.html">07 - Analysing change, continuously (Part 2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mathscourse/lecture08/08_Calculating_accumulated_change.html">08 - Calculating accumulated change</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mathscourse/tutorials/lecture01/Tutorial_01.html">Tutorial 01</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mathscourse/tutorials/lecture05/Tutorial_05.html">Tutorial 05</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mathscourse/tutorials/lecture06/Tutorial_06.html">Tutorial 06</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Basic Data Analyses and Statistics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Stats-Intro.html">Basic Data Science and Statistics: Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="Data_R.html">Data Management and Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="ExpDesign.html">Experimental design and Data exploration</a></li>
<li class="toctree-l1"><a class="reference internal" href="t_F_tests.html">Basic hypothesis testing: <span class="math notranslate nohighlight">\(t\)</span> and <span class="math notranslate nohighlight">\(F\)</span> tests</a></li>
<li class="toctree-l1"><a class="reference internal" href="regress.html">Linear Models: Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="anova.html">Linear Models: Analysis of variance</a></li>
<li class="toctree-l1"><a class="reference internal" href="MulExpl.html">Linear Models: Multiple explanatory variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="MulExplInter.html">Linear Models: Multiple variables with interactions</a></li>
<li class="toctree-l1"><a class="reference internal" href="ModelSimp.html">Model simplification</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Advanced Data Analyses and Statistics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="glm.html">Generalised Linear Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="ModelFitting-NLLS.html">Model Fitting using Non-linear Least-squares</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendices</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Appendix-JupyIntro.html">Introduction to Jupyter</a></li>
<li class="toctree-l1"><a class="reference internal" href="Appendix-Data-Python.html">Data analyses  with Python &amp; Jupyter</a></li>
<li class="toctree-l1"><a class="reference internal" href="Appendix-Maths.html">Mathematical models in Jupyter</a></li>
<li class="toctree-l1"><a class="reference internal" href="Appendix-Databases.html">Databases <span class="tocSkip"></span></a></li>
<li class="toctree-l1"><a class="reference internal" href="Appendix-NLLS-Python.html">Model fitting in Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="Appendix-MiniProj.html">The Computing Miniproject</a></li>
<li class="toctree-l1"><a class="reference internal" href="Appendix-Assessment.html">TMQB Coursework Assessment</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Introduction to High-Performance Computing (HPC)</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/mhasoba/TheMulQuaBio" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/mhasoba/TheMulQuaBio/issues/new?title=Issue%20on%20page%20%2Fnotebooks/Appendix-HighPerformanceComputing.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/notebooks/Appendix-HighPerformanceComputing.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Introduction to High-Performance Computing (HPC)</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-use-hpc">Why Use HPC?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-computer-hardware-vocabulary">Key Computer Hardware Vocabulary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hpc-systems">HPC Systems</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#clusters">Clusters</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#supercomputers">Supercomputers</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#distributed-systems">Distributed Systems</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#serial-vs-parallel-processing">Serial vs Parallel Processing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#serial-processing">Serial Processing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#parallel-processing">Parallel Processing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-parallelism">Types of Parallelism</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hpc-workflows-and-use-cases">HPC Workflows and Use Cases</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#embarrassingly-parallel-tasks">Embarrassingly Parallel Tasks</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#high-throughput-computing-htc">High Throughput Computing (HTC)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#memory-intensive-tasks">Memory-Intensive Tasks</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#job-arrays">Job Arrays</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#trade-offs">Trade-offs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#local-parallelisation">Local Parallelisation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#getting-set-up-on-the-imperial-hpc">Getting Set Up on the Imperial HPC</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#running-a-job-on-the-imperial-hpc">Running a job on the Imperial HPC</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="introduction-to-high-performance-computing-hpc">
<h1>Introduction to High-Performance Computing (HPC)<a class="headerlink" href="#introduction-to-high-performance-computing-hpc" title="Link to this heading">#</a></h1>
<p>High-Performance Computing (HPC) refers to the use of supercomputers or parallel computing techniques to perform complex computations quickly. HPC systems aggregate computing resources to solve problems that would be unfeasible or time-consuming using conventional methods. These systems play a critical role in research fields like bioinformatics, physics, climate modeling, and engineering.</p>
<section id="why-use-hpc">
<h2>Why Use HPC?<a class="headerlink" href="#why-use-hpc" title="Link to this heading">#</a></h2>
<p>High-Performance computing is a game-changer for tackling some of the most challenging problems today in science, engineering, and data analysis. Imagine you are working with a data set so large that a normal desktop computer would take days to weeks to process it - HPCs are able to handle the task in hours or even minutes because of the combined power of many interconnected processors and computers, enabling the simultaneous processing of data. For example, fields like genomics rely on HPC to analyse DNA sequences across entire populations, while climate scientists use it to model weather patterns with high accuracy. Similarly, researchers working on optimisation problems, such as desgigning efficient supply chains or fluid dynamics depend on HPC to handle the scale of calculations involved in their modelling.</p>
<p>But how do HPCs achieve better results in less time? This is because of parallel computing, which is the ability to divide large tasks into smaller pieces that can be completed simultaneously. You can think of this like a group of people working together to build a house - each person has a specific task which they work on at the same time, finishing the job faster. In genomics, for example, modern sequence alignment methods align genomes by splitting up the sequences, and aligning individual chunks to each other until they are successfully aligned, in parallel - a much more efficient method than loading entire genomes (hundreds of millions, to even billions of nucleotides) and placing each genome alongside another to match it, sequentially.</p>
<p>So, when should you consider using HPC?</p>
<ul class="simple">
<li><p>If you’re running simulations that require thousands of iterations—like predicting how a hurricane might behave over time—or working with massive datasets, such as analyzing millions of genomic sequences, HPC is essential.</p></li>
<li><p>It’s also a great choice when your tasks can be automated, like running multiple models or simulations at once, freeing you to focus on interpreting the results. HPC systems are particularly powerful for long-running tasks that demand significant memory or computational power, making them ideal for tasks that go far beyond the capabilities of standard desktop computers.</p></li>
</ul>
<p>By mastering key high-performance computing concepts, you’ll gain an understanding of how problems can be approached more efficiently, tackle larger datasets, and expand the scale of what’s possible in your field.</p>
</section>
<hr class="docutils" />
<section id="key-computer-hardware-vocabulary">
<h2>Key Computer Hardware Vocabulary<a class="headerlink" href="#key-computer-hardware-vocabulary" title="Link to this heading">#</a></h2>
<p>It’s good to first familiarise yourself with some computer hardware terms that are frequently used. Whether you’re running code locally or on an HPC, you can run into limitations with system you are using, informing not only your methods development and hardware optimisation, but also allows you to troubleshoot performance issues and make informed decisions about how to structure your computational tasks.</p>
<ul class="simple">
<li><p><strong>CPU (Central Processing Unit)</strong> – Often referred to as the computer’s
“brain,” the CPU is responsible for executing instructions, managing
data, and interacting with memory. In all modern computers, including
HPCs, CPUs consist of multiple cores that allow for the simultaneous
execution of multiple instructions.</p></li>
<li><p><strong>CPU Core</strong> – A core is a processing unit within a CPU that can execute
instructions independently. Cores are designed to handle multiple
threads, enabling more efficient processing of tasks. Each core and
thread can execute its own set of instructions, allowing for parallel
execution of workloads, which is essential for complex computations and
multitasking.</p></li>
<li><p><strong>Thread</strong> – A thread is the smallest unit of execution within a
process. In most modern high-performance computing (HPC) systems,
processes are divided into threads rather than cores, allowing for
efficient resource utilisation through multithreading. This enables
multiple threads to run concurrently, maximising CPU utilisation and
speeding up tasks like data processing, simulations, and scientific
computations.</p></li>
<li><p><strong>GPU (Graphics Processing Unit)</strong> – Initially developed to manage
visual tasks, GPUs are now widely used in parallel programming for
handling large volumes of basic arithmetic operations, primarily through
matrix multiplications. They are highly efficient at processing many
calculations simultaneously, making them ideal for scientific
computations and machine learning applications.</p></li>
<li><p><strong>Random Access Memory (RAM)</strong> – Usually referred to as just “memory”, RAM is the temporary storage that the
CPU uses to hold data actively being processed. RAM allows for quick
access to data needed for computations, which is either deleted or
deposited into NVM storage once completed.</p></li>
<li><p><strong>Non-Volatile Memory (NVM)</strong> - Non-volatile memory refers to any form
of memory that retains data even when the system is powered off. This
includes storage devices like hard drives (HDDs), solid-state drives
(SSDs), and flash drives. Unlike RAM, which is cleared when the system
shuts down, NVM provides long-term data storage, allowing for the
preservation of files, applications, and system states across power
cycles.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="hpc-systems">
<h2>HPC Systems<a class="headerlink" href="#hpc-systems" title="Link to this heading">#</a></h2>
<section id="clusters">
<h3>Clusters<a class="headerlink" href="#clusters" title="Link to this heading">#</a></h3>
<p>An HPC cluster is a collection of interconnected computers (nodes) that
work together. Each node in a cluster is typically a standard server or
workstation, but together they behave as a single powerful system.
Clusters are commonly used in scientific research because they can be
built using off-the-shelf hardware.</p>
</section>
<section id="supercomputers">
<h3>Supercomputers<a class="headerlink" href="#supercomputers" title="Link to this heading">#</a></h3>
<p>Supercomputers are specialised machines designed for high-speed
computations. They consist of thousands (or even millions) of processors
working together to complete a single task, often composed of many
cluster nodes or purpose-built platforms (e.g., NVIDIA DGX GH200) . They
are optimised for performance, providing the highest level of
computational power.</p>
</section>
<section id="distributed-systems">
<h3>Distributed Systems<a class="headerlink" href="#distributed-systems" title="Link to this heading">#</a></h3>
<p>Distributed systems consist of computers that are geographically spread
but connected over a network. These systems allow for distributed
computing, where different parts of a computation are handled by
different machines. Drawbacks of this include data transfer, a</p>
</section>
</section>
<hr class="docutils" />
<section id="serial-vs-parallel-processing">
<h2>Serial vs Parallel Processing<a class="headerlink" href="#serial-vs-parallel-processing" title="Link to this heading">#</a></h2>
<section id="serial-processing">
<h3>Serial Processing<a class="headerlink" href="#serial-processing" title="Link to this heading">#</a></h3>
<p>Serial (or sequential) programming is the execution of tasks in a
step-by-step, linear sequence where only one instruction is processed at
a time. In this model, the processor completes one task before starting
the next, with no overlap or concurrency. While this method is simple
and efficient for small, straightforward tasks, it becomes a bottleneck
for larger problems requiring extensive computation.</p>
<figure class="align-default" id="id1">
<img alt="../_images/serialProblem.png" src="../_images/serialProblem.png" />
<figcaption>
<p><span class="caption-number">Fig. 33 </span><span class="caption-text">Serial programming chain of operations (<a class="reference external" href="https://hpc.llnl.gov/training/tutorials/introduction-parallel-computing-tutorial">https://hpc.llnl.gov/training/tutorials/introduction-parallel-computing-tutorial</a>)</span><a class="headerlink" href="#id1" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="parallel-processing">
<h3>Parallel Processing<a class="headerlink" href="#parallel-processing" title="Link to this heading">#</a></h3>
<p>At the heart of HPC is <strong>parallel computing</strong>, where multiple
calculations or processes are performed simultaneously. This is
typically achieved by dividing tasks among multiple processors, which
work together to complete a job faster than a single processor could.</p>
<p>A frequent misunderstanding is that executing code on a cluster will
automatically result in improved performance. Clusters do not inherently
accelerate code execution; for enhanced performance, the code must be
explicitly adapted for parallel processing, a task that falls under
<strong>your</strong> responsibility as a programmer.</p>
<figure class="align-default" id="id2">
<img alt="../_images/parallelProblem.png" src="../_images/parallelProblem.png" />
<figcaption>
<p><span class="caption-number">Fig. 34 </span><span class="caption-text">Parallel programming chain of operations (<a class="reference external" href="https://hpc.llnl.gov/training/tutorials/introduction-parallel-computing-tutorial">https://hpc.llnl.gov/training/tutorials/introduction-parallel-computing-tutorial</a>)</span><a class="headerlink" href="#id2" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="types-of-parallelism">
<h3>Types of Parallelism<a class="headerlink" href="#types-of-parallelism" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Data Parallelism</strong>: Divides large datasets into smaller chunks,
which are processed simultaneously. Each processor works on a
different piece of data.</p></li>
<li><p><strong>Task Parallelism</strong>: Different processors perform different tasks
simultaneously. Each processor works on a separate part of the
overall computation.</p></li>
<li><p><strong>Hybrid Parallelism</strong>: A combination of both data and task
parallelism, where both the tasks and data are split across multiple
processors.</p></li>
</ol>
</section>
</section>
<hr class="docutils" />
<section id="hpc-workflows-and-use-cases">
<h2>HPC Workflows and Use Cases<a class="headerlink" href="#hpc-workflows-and-use-cases" title="Link to this heading">#</a></h2>
<section id="embarrassingly-parallel-tasks">
<h3>Embarrassingly Parallel Tasks<a class="headerlink" href="#embarrassingly-parallel-tasks" title="Link to this heading">#</a></h3>
<p>Some tasks are naturally suited for parallelisation, often referred to
as “embarrassingly parallel.” This means that each part of the task can
be executed independently without any need for communication between
processors. Examples include:</p>
<ul class="simple">
<li><p><strong>Image rendering</strong>: Each pixel or frame can be calculated
separately.</p></li>
<li><p><strong>Monte Carlo simulations</strong>: Each iteration is independent of the
others.</p></li>
</ul>
</section>
<section id="high-throughput-computing-htc">
<h3>High Throughput Computing (HTC)<a class="headerlink" href="#high-throughput-computing-htc" title="Link to this heading">#</a></h3>
<p>In some cases, a large number of relatively simple operations need to be
performed. <strong>High-throughput computing</strong> is a paradigm where many
independent jobs are processed concurrently. This is useful in:</p>
<ul class="simple">
<li><p><strong>Bioinformatics</strong>: Performing sequence alignments or genome
annotations.</p></li>
<li><p><strong>Data processing</strong>: Handling large datasets where each piece can be
processed individually.</p></li>
</ul>
</section>
<section id="memory-intensive-tasks">
<h3>Memory-Intensive Tasks<a class="headerlink" href="#memory-intensive-tasks" title="Link to this heading">#</a></h3>
<p>HPC systems are ideal for tasks that require more memory than is
available on a local machine. Large-scale data analysis or the
visualisation of vast datasets often requires enormous amounts of
memory.</p>
</section>
</section>
<hr class="docutils" />
<section id="job-arrays">
<h2>Job Arrays<a class="headerlink" href="#job-arrays" title="Link to this heading">#</a></h2>
<p>A job array consists of multiple “tasks” that perform the same job but
with different parameters or datasets. This approach is especially
useful when you have many independent simulations, analyses, or
calculations that can run in parallel.</p>
<p>Job arrays are an essential feature of HPC systems that allow users to
submit a large number of similar tasks simultaneously. Instead of
submitting multiple jobs manually, you can use a job array to submit a
series of jobs with a single command.</p>
<p>For example, imagine you need to run the same simulation 100 times with
different input parameters. Instead of submitting 100 individual jobs,
you can create a job array that runs all the simulations simultaneously.</p>
</section>
<hr class="docutils" />
<section id="trade-offs">
<h2>Trade-offs<a class="headerlink" href="#trade-offs" title="Link to this heading">#</a></h2>
<p>While HPC provides tremendous computational power, there are some
trade-offs:</p>
<ol class="arabic simple">
<li><p><strong>Setup Time</strong>: Configuring jobs on an HPC cluster can be
time-consuming, requiring careful management of resources such as
memory, CPU, and runtime limits.</p></li>
<li><p><strong>Parallelisation Overhead</strong>: Not all tasks benefit equally from
parallelisation. In some cases, the overhead involved in
coordinating multiple processors may diminish the performance gains.</p></li>
<li><p><strong>Learning Curve</strong>: Using HPC often requires learning job submission
systems (e.g., Slurm, PBS) and optimising code for parallel
execution, which may be challenging for new users.</p></li>
</ol>
<p>It is important to consider the extent of realised gains of
parallelisation when using HPC systems. The ideal setup of any computing
system would allow for scalable parallelisation in which doubling the
number of processes will double the speed of a job. Amdahl’s Law allows
us to predict theoretical speedups in parallelised computing jobs, where
the idealised speedup scales almost linearly with increasing division of
labor across processors, but is ultimately restricted by the portion of
the program that cannot be parallelised.</p>
<p><strong>In real life, gains under Amdahl’s Law cannot be realised.</strong> As
programmers looking to parallelise our work, we have to take into
consideration computer structures, and primarily their latency in
transferring data across systems. All networks, whether they are between
cores, processors, nodes, or entire clusters, have non-zero transfer
latency and limited bandwidth, meaning the speed of communication
between them does not happen infinitely fast.</p>
<ul class="simple">
<li><p>We can expect that the more we split processes, the more that
latency issues will reduce the efficiency of parallelisation,
especially as the complexity of the system increases.</p></li>
</ul>
<p>Shown in the example figure below, we see minimal trade-offs from ideal
speedups from 1-16 cores in this system they increase as we escape from
the smaller bounds of core-core latency and reach cpu-cpu latency at 32,
with significant bottlenecks after 128 threads where we use 7 whole
compute nodes (i.e. 7 separate computers)!</p>
<figure class="align-default" id="id3">
<img alt="../_images/speedup.png" src="../_images/speedup.png" />
<figcaption>
<p><span class="caption-number">Fig. 35 </span><span class="caption-text">Speedup achieved from ideal parallelisation vs realised (Data from: <a class="reference external" href="https://hpc-wiki.info/hpc/Scaling">https://hpc-wiki.info/hpc/Scaling</a>)</span><a class="headerlink" href="#id3" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>The realised speedup diverges so much from ideal because of the
increased latency in communicating and transferring data between the
many nodes used in this system.</p></li>
</ul>
<p>This divergence can occur on smaller scales, not just between nodes,
where we may have a CPU with hundreds of threads - just take a look at
one of the latest processor’s from AMD, for example the EPYC 9965, each
having over 384 threads. <strong>The distribution of information across that
many independent pathways can be a struggle, and should be considered
when designing parallelisation workflows.</strong></p>
</section>
<hr class="docutils" />
<section id="local-parallelisation">
<h2>Local Parallelisation<a class="headerlink" href="#local-parallelisation" title="Link to this heading">#</a></h2>
<p>Local parallelisation on a laptop, desktop, or workstation can
significantly improve performance by harnessing the full potential of
multi-core CPUs in a controlled environment. While HPCs are tailored for
massive computations, local parallelisation on personal devices offers
the ability to speed up individual, day-to-day applications.</p>
<p>Parallelising your code locally is ideal for repetitive computations or
simulations, such as running the same model on different datasets,
bootstrapping analyses, or performing parameter sweeps. By dividing each
repetition across cores, you can perform these tasks simultaneously
rather than sequentially, reducing execution time significantly. This is
particularly useful for tasks like cross-validation or Monte Carlo
simulations, where each iteration is independent and benefits from being
run in parallel.</p>
<ul class="simple">
<li><p>In R, the <code class="docutils literal notranslate"><span class="pre">parallel</span></code> package gives us access to parallelisation
functions, such as <code class="docutils literal notranslate"><span class="pre">mclapply</span></code> (multi-core <code class="docutils literal notranslate"><span class="pre">lapply</span></code>) Additional
packages include future and foreach.</p></li>
<li><p>Python also has powerful libraries for parallel computing, such as
<code class="docutils literal notranslate"><span class="pre">multiprocessing</span></code> and <code class="docutils literal notranslate"><span class="pre">concurrent.futures</span></code>. Both libraries provide
straightforward ways to parallelise tasks locally.</p></li>
</ul>
<p>Below is an example of parallelised model fitting using <code class="docutils literal notranslate"><span class="pre">mclapply</span></code> in
the <code class="docutils literal notranslate"><span class="pre">parallel</span></code> package in <code class="docutils literal notranslate"><span class="pre">R</span></code>. In this code chunk, we generate example
data that is grouped by an <code class="docutils literal notranslate"><span class="pre">ID</span></code> column and we want to apply a linear
model to each <code class="docutils literal notranslate"><span class="pre">ID</span></code> group. First we can generate the data:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>n &lt;- 10000   # Number of observations

data &lt;- data.frame(
  ID = sample(1:10, n, replace = TRUE),  # ID column to define 10 groups
  y = rnorm(n),
  X = rnorm(n)
)
</pre></div>
</div>
<p>We can then split the data into a list of data sets, which allows us to
use a list-apply function like <code class="docutils literal notranslate"><span class="pre">lapply/mclapply</span></code>, and define our
function for outputting the coefficients for the corresponding <code class="docutils literal notranslate"><span class="pre">ID</span></code>
group:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>library(dplyr)

data_groups &lt;- data %&gt;% group_by(ID) %&gt;% group_split() # Split the data by ID

# Define a function to fit a linear model for each group
fit_model &lt;- function(group_data) {
  model &lt;- lm(y ~ X, data = group_data)
  coef_df &lt;- as.data.frame(t(coef(model)))
  coef_df$ID &lt;- unique(group_data$ID)  # Add ID for reference
  return(coef_df)
}
</pre></div>
</div>
<p>Finally, we should parallelise the code by identifying the number of
cores our system has, avoiding hard coding this information - keep this
in mind if you want others to run it on a different system! We may also
want to leave one core for general system processes. As we have applied
this onto a list we want to consider bringing this information back
together, using a function like <code class="docutils literal notranslate"><span class="pre">bind_rows</span></code>.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>library(parallel)

num_cores &lt;- detectCores() - 1 # Use all cores but one

results &lt;- mclapply(data_groups, fit_model, mc.cores = num_cores) # Fit the models

final_results &lt;- bind_rows(results) # Bind model outputs from list to table
print(final_results)
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="getting-set-up-on-the-imperial-hpc">
<h2>Getting Set Up on the Imperial HPC<a class="headerlink" href="#getting-set-up-on-the-imperial-hpc" title="Link to this heading">#</a></h2>
<p>You can find all information about getting started and working on the
Imperial HPC here:
<a class="reference external" href="https://icl-rcs-user-guide.readthedocs.io">icl-rcs-user-guide.readthedocs.io</a></p>
<p>To get started, you will need 4 things:</p>
<ol class="arabic">
<li><p><strong>Access to the HPC system:</strong> You should have received an email from
<a class="reference external" href="mailto:noreply&#37;&#52;&#48;imperial&#46;ac&#46;uk">noreply<span>&#64;</span>imperial<span>&#46;</span>ac<span>&#46;</span>uk</a> with the subject heading “Welcome from the
Research Computing Service”. If you have not received this email,
please let me know as soon as possible so we can try and get you
added this week.</p></li>
<li><p><strong>A method of working on the cluster:</strong> The cluster is accessed
using Secure Shell (SSH). If you are using Linux or macOS then you
should have OpenSSH already installed alongside your operating
system, which can be accessed from a terminal session such as
command prompt. You can double check that this is available to you
by logging into the HPC service for the first time. In a terminal
session, enter the following, substituting your own username (in the
form abc123), and entering your Imperial password when prompted:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="w"> </span>sftp<span class="w"> </span>username@login.hpc.imperial.ac.uk
</pre></div>
</div>
<p>If this has been successful, you will see a message containing the title “Imperial College London Research Computing Service”</p>
</li>
<li><p><strong>Necessary modules are set up in your remote are:</strong> It will be
useful to ensure that Python and R are set up on your area of the
HPC system at this stage. You will only need to do this once. To
install Python and R, you will need to first log in to the HPC
service (as covered in the above section), and then enter the
following two lines into the command line within your area of the
remote system:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>module<span class="w"> </span>load<span class="w"> </span>anaconda3/personal
anaconda-setup
</pre></div>
</div>
<p>This could take some time and may require you to respond “yes” when prompted. Once anaconda is fully installed, install R by entering</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>conda<span class="w"> </span>install<span class="w"> </span>R
</pre></div>
</div>
<p>Once again, this could take some time and may require you to respond “yes” when prompted. Once both of these are installed, you should be able to enter python3 and code in Python on the cluster   node. However, in general you should only run code in either R or Python by submitting them within jobs (as covered in the lectures and in the instructions document). (You will notice that if    you attempt to launch R from your HPC node you will be given a stern message!)</p>
</li>
<li><p><strong>A method of file transfer:</strong> Files are exchanged between your
local machine and your area on the HPC system using Secure File
Transfer Protocol (SFTP). If you are working in Linux or macOS, you
should be able to achieve this directly from the terminal. To check
this, enter the following and enter your password when prompted:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sftp<span class="w"> </span>username@login.hpc.imperial.ac.uk
</pre></div>
</div>
<p>Once you are logged in, type and enter pwd to find out which area of the system you are in. By default you should land in username$HOME, and by entering put filename.R this file should be        copied from your current local directory to your current remote directory. You can also similarly use the Secure Copy (SCP) method to transfer files – this, and further information about         copying and getting files to/from the remote directory, will be covered in the main instruction document</p>
</li>
</ol>
</section>
<hr class="docutils" />
<section id="running-a-job-on-the-imperial-hpc">
<h2>Running a job on the Imperial HPC<a class="headerlink" href="#running-a-job-on-the-imperial-hpc" title="Link to this heading">#</a></h2>
<p>You first must determine the task at hand. Are you running your own
script or software that natively parallelises tasks? Is your job an
array?</p>
<p>Using arrays as an example, we would first want to make an R or Python
script that takes in a job number and uses that to determine which task
to perform. The <code class="docutils literal notranslate"><span class="pre">HPC_script.R/py</span></code> files below, when sourced, identify
the job number (that is, the job number the Imperial HPC assigns to our
code submission), run our code, and then save the outputs to the current
working directory, with all file names being distinct (otherwise the
different jobs will overwrite each other).</p>
<p><strong>In R:</strong></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>seed_number &lt;- as.numeric(Sys.getenv(&quot;PBS_ARRAY_INDEX&quot;)) # Find out the job number

set.seed(seed_number) # Set this as the random seed so that all runs have a unique seed

output &lt;- runif(n=10000,min=0,max=1) # # Run whatever simulation we want

save(output,file=paste(&quot;output_&quot;,seed_number,&quot;.rda&quot;)) # Save this to a file

rm(output,seed_number) # Remove our objects from the environment
</pre></div>
</div>
<p><strong>Similarly, in Python:</strong></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>seed_number = int(os.getenv(&quot;PBS_ARRAY_INDEX&quot;)) # Find out the job number

seed(seed_number) # Set this as the random seed so that all runs have a unique seed

output = numpy.random.uniform(0,1,1000) # Run whatever simulation we want

with open(print(&quot;output_&quot;,str(seed_number),&quot;.data&quot;,sep=&quot;&quot;),&quot;w&quot;) as f:
  f.write(output) # Save this to a file
  
del seed_number # Remove our objects from the environment
del output
</pre></div>
</div>
<p>Using SFTP or SCP from the terminal of your local machine, copy your
task script to an area on the remote machine (e.g.,
<code class="docutils literal notranslate"><span class="pre">$HOME/HPC_script.R</span></code>).</p>
<p>To run your job on the HPC, you must write a .sh file to provide the
cluster with instructions to run the task script. This will reference
your task script, so you will need to be mindful of the relative file
path. This file must contain the following fields at the top:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>#!/bin/bash
#PBS -l select=N:ncpus=X:mem=Ygb
#PBS -l walltime=HH:00:00
</pre></div>
</div>
<p>This will determine the queue that your job gets put into. If your
requested specifications do not fall within at least one queue, your job
won’t run! Have a look at the <a class="reference external" href="https://icl-rcs-user-guide.readthedocs.io/en/latest/hpc/queues/job-sizing-guidance/">RCS job sizing
guidance</a>
for more information.</p>
<p>Within this file, you will generally want to load any modules and
packages, print any statements to check your progress within the job
output files, and transfer files to and from the job to your working
directory. <strong>For your outputs to be created correctly, you must move
your files to <code class="docutils literal notranslate"><span class="pre">$TMPDIR</span></code> to be processed, and then move files from this
back to <code class="docutils literal notranslate"><span class="pre">$HOME</span></code></strong>. This is because <code class="docutils literal notranslate"><span class="pre">$TMPDIR</span></code> is where your files are
run, whereas <code class="docutils literal notranslate"><span class="pre">$HOME</span></code> is where you interact with them!</p>
<p>This can be summarised in the <code class="docutils literal notranslate"><span class="pre">run_script.sh</span></code> file below, where we are
running the <code class="docutils literal notranslate"><span class="pre">HPC_script.R</span></code> file from above. Because the R script does
not parallelise within it and does not load a significant amount of
data, we will only request a single thread (<code class="docutils literal notranslate"><span class="pre">ncpus</span></code>) and 1GB of RAM
(<code class="docutils literal notranslate"><span class="pre">mem</span></code>):</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>#!/bin/bash
#PBS -l walltime=12:00:00
#PBS -l select=1:ncpus=1:mem=1gb

module load anaconda3/personal

echo &quot;R is about to run&quot;

cp $HOME/HPC_script.R $TMPDIR

R --vanilla &lt; $TMPDIR/HPC_script.R

mv $TMPDIR/output_* $HOME/output_files/

echo &quot;R has finished running&quot;
</pre></div>
</div>
<p>The Imperial HPC uses the PBS Pro job scheduler (documentation available
<a class="reference external" href="https://2021.help.altair.com/2021.1.2/PBS%20Professional/PBSUserGuide2021.1.2.pdf">here</a>),
whereas other systems may use SLURM (documentation available
<a class="reference external" href="https://slurm.schedmd.com/documentation.html">here</a>). To submit your
job to the queue you will use the <code class="docutils literal notranslate"><span class="pre">qsub</span></code> command. If you are submitting
an array job, as we are with <code class="docutils literal notranslate"><span class="pre">run_script.sh</span></code>, you want to use the <code class="docutils literal notranslate"><span class="pre">-J</span></code>
option and specify the number of jobs to run. In this case:
<code class="docutils literal notranslate"><span class="pre">qsub</span> <span class="pre">-J</span> <span class="pre">1-32</span> <span class="pre">run_script.sh</span></code> (tells the cluster to do 32 runs based on
the .sh file - the job number will be from 1-32). Additionally:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">qstat</span></code> - tells you the job ID and its current status</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">qdel</span> <span class="pre">jobID</span></code> - cancels the job</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cat</span> <span class="pre">filename.sh.ejobID</span></code> - are error files empty?</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cat</span> <span class="pre">filename.sh.ojobID</span></code> - are standard output files as expected?</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="Appendix-Assessment.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">TMQB Coursework Assessment</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-use-hpc">Why Use HPC?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-computer-hardware-vocabulary">Key Computer Hardware Vocabulary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hpc-systems">HPC Systems</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#clusters">Clusters</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#supercomputers">Supercomputers</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#distributed-systems">Distributed Systems</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#serial-vs-parallel-processing">Serial vs Parallel Processing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#serial-processing">Serial Processing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#parallel-processing">Parallel Processing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-parallelism">Types of Parallelism</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hpc-workflows-and-use-cases">HPC Workflows and Use Cases</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#embarrassingly-parallel-tasks">Embarrassingly Parallel Tasks</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#high-throughput-computing-htc">High Throughput Computing (HTC)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#memory-intensive-tasks">Memory-Intensive Tasks</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#job-arrays">Job Arrays</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#trade-offs">Trade-offs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#local-parallelisation">Local Parallelisation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#getting-set-up-on-the-imperial-hpc">Getting Set Up on the Imperial HPC</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#running-a-job-on-the-imperial-hpc">Running a job on the Imperial HPC</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By TheMulQuaBio collective!
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>